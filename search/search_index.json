{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CausalPipe Documentation","text":"<p>Welcome to the documentation for CausalPipe, a Python package that simplifies causal discovery and analysis. CausalPipe wraps around Causal-Learn and Lavaan to provide an easy-to-use, step-by-step process for performing causal analysis.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Data Preprocessing: Handles missing data with multiple imputation, standardizes variables, and encodes categorical variables.</li> <li>Causal Discovery: Construct causal graphs using methods like Fast Adjacency Search (FAS) or Bootstrap-based Causal Structure Learning (BCSL).</li> <li>Edge Orientation: Use algorithms such as Fast Causal Inference (FCI) or Hill Climbing to orient edges in causal graphs.</li> <li>Causal Effect Estimation: Estimate effects using methods such as Partial Correlation, Structural Equation Modeling (SEM), or kernel methods.</li> <li>Symbolic Regression: Integrate PySR to learn nonlinear structural equations and score cyclic models via pseudo-likelihood or MMD<sup>2</sup>.</li> <li>Visualization: Visualize correlation graphs, causal graphs, and SEM results.</li> </ul>"},{"location":"#configuration-classes","title":"Configuration Classes","text":"<p>CausalPipe is configured through a collection of dataclasses that define each step of the pipeline:</p> <ul> <li>VariableTypes \u2013 declare continuous, ordinal, and nominal variables.</li> <li>DataPreprocessingParams \u2013 control imputation, standardization, and   feature filtering.</li> <li>Skeleton methods \u2013 <code>FASSkeletonMethod</code>, <code>BCSLSkeletonMethod</code>.</li> <li>Orientation methods \u2013 <code>FCIOrientationMethod</code>,   <code>HillClimbingOrientationMethod</code>.</li> <li>Causal effect methods \u2013 <code>PearsonCausalEffectMethod</code>,   <code>SpearmanCausalEffectMethod</code>, <code>MICausalEffectMethod</code>,   <code>KCICausalEffectMethod</code>, <code>SEMCausalEffectMethod</code>,   <code>SEMClimbingCausalEffectMethod</code>, <code>PYSRCausalEffectMethod</code>,   <code>PYSRCausalEffectMethodHillClimbing</code>.</li> </ul>"},{"location":"api_reference/","title":"API Reference","text":"<p>Welcome to the CausalPipe API Reference. This section provides detailed information about the classes, methods, and functions available in the CausalPipe package. Whether you're integrating CausalPipe into your workflow or extending its functionality, this guide will help you navigate its components effectively.</p>"},{"location":"api_reference/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Classes</li> <li>CausalPipe</li> <li>CausalPipeConfig<ul> <li>VariableTypes</li> <li>DataPreprocessingParams</li> <li>SkeletonMethod</li> <li>BCSLSkeletonMethod</li> <li>FASSkeletonMethod</li> <li>OrientationMethod</li> <li>FCIOrientationMethod</li> <li>HillClimbingOrientationMethod</li> <li>CausalEffectMethod</li> <li>PearsonCausalEffectMethod</li> <li>SpearmanCausalEffectMethod</li> <li>MICausalEffectMethod</li> <li>KCICausalEffectMethod</li> <li>SEMCausalEffectMethod</li> <li>SEMClimbingCausalEffectMethod</li> <li>PYSRCausalEffectMethod</li> <li>PYSRCausalEffectMethodHillClimbing</li> </ul> </li> <li>SEMScore</li> <li>Functions</li> <li>fit_sem_lavaan</li> <li>search_best_graph_climber</li> </ul>"},{"location":"api_reference/#classes","title":"Classes","text":""},{"location":"api_reference/#causalpipe","title":"CausalPipe","text":"<p><code>CausalPipe</code> is the core class of the CausalPipe package. It orchestrates the entire causal discovery pipeline, handling data preprocessing, skeleton identification, edge orientation, and causal effect estimation.</p>"},{"location":"api_reference/#initialization","title":"Initialization","text":"<pre><code>CausalPipe(config: CausalPipeConfig)\n</code></pre> <ul> <li>Parameters:<ul> <li><code>config</code> (<code>CausalPipeConfig</code>): A comprehensive configuration object that defines variable types, preprocessing parameters, skeleton identification methods, edge orientation methods, and causal effect estimation methods.</li> </ul> </li> </ul>"},{"location":"api_reference/#methods","title":"Methods","text":""},{"location":"api_reference/#preprocess_datadf-pddataframe-optionalpddataframe","title":"<code>preprocess_data(df: pd.DataFrame) -&gt; Optional[pd.DataFrame]</code>","text":"<p>Preprocesses the input DataFrame based on the specified parameters in the configuration. This includes handling missing values, encoding categorical variables, standardizing features, and performing feature selection.</p> <ul> <li> <p>Parameters:</p> <ul> <li><code>df</code> (<code>pd.DataFrame</code>): Raw input data.</li> </ul> </li> <li> <p>Returns:</p> <ul> <li><code>Optional[pd.DataFrame]</code>: Preprocessed data ready for causal discovery, or <code>None</code> if an error occurred.</li> </ul> </li> </ul>"},{"location":"api_reference/#identify_skeletondf-optionalpddataframe-none-show_plots-optionalbool-none-optionaltuplegeneralgraph-dicttupleint-int-setint","title":"<code>identify_skeleton(df: Optional[pd.DataFrame] = None, show_plots: Optional[bool] = None) -&gt; Optional[Tuple[GeneralGraph, Dict[Tuple[int, int], Set[int]]]]</code>","text":"<p>Identifies the global skeleton of the causal graph using the specified method (e.g., FAS or BCSL).</p> <ul> <li> <p>Parameters:</p> <ul> <li><code>df</code> (<code>Optional[pd.DataFrame]</code>): Raw input data. If <code>None</code>, uses preprocessed data.</li> <li><code>show_plots</code> (<code>Optional[bool]</code>): Whether to display plots. Overrides the default setting.</li> </ul> </li> <li> <p>Returns:</p> <ul> <li><code>Optional[Tuple[GeneralGraph, Dict[Tuple[int, int], Set[int]]]]</code>: The undirected graph and sepsets, or <code>None</code> if an error occurred.</li> </ul> </li> </ul>"},{"location":"api_reference/#orient_edgesdf-optionalpddataframe-none-show_plot-bool-false-optionalgeneralgraph","title":"<code>orient_edges(df: Optional[pd.DataFrame] = None, show_plot: bool = False) -&gt; Optional[GeneralGraph]</code>","text":"<p>Orients the edges of the skeleton using the specified orientation method (e.g., FCI or Hill Climbing).</p> <ul> <li> <p>Parameters:</p> <ul> <li><code>df</code> (<code>Optional[pd.DataFrame]</code>): Raw input data. If <code>None</code>, uses preprocessed data.</li> <li><code>show_plot</code> (<code>bool</code>): Whether to display the resulting graph.</li> </ul> </li> <li> <p>Returns:</p> <ul> <li><code>Optional[GeneralGraph]</code>: The directed graph, or <code>None</code> if an error occurred.</li> </ul> </li> </ul>"},{"location":"api_reference/#estimate_causal_effectsdf-optionalpddataframe-none-show_plot-bool-false-optionaldictstr-any","title":"<code>estimate_causal_effects(df: Optional[pd.DataFrame] = None, show_plot: bool = False) -&gt; Optional[Dict[str, Any]]</code>","text":"<p>Estimates causal effects using the specified methods (e.g., Partial Correlation, SEM).</p> <ul> <li> <p>Parameters:</p> <ul> <li><code>df</code> (<code>Optional[pd.DataFrame]</code>): Raw input data. If <code>None</code>, uses preprocessed data.</li> <li><code>show_plot</code> (<code>bool</code>): Whether to display plots.</li> </ul> </li> <li> <p>Returns:</p> <ul> <li><code>Optional[Dict[str, Any]]</code>: The estimated causal effects, or <code>None</code> if an error occurred.</li> </ul> </li> </ul>"},{"location":"api_reference/#run_pipelinedf-pddataframe","title":"<code>run_pipeline(df: pd.DataFrame)</code>","text":"<p>Executes the full causal discovery pipeline: preprocessing, skeleton identification, edge orientation, and causal effect estimation.</p> <ul> <li>Parameters:</li> <li><code>df</code> (<code>pd.DataFrame</code>): Raw input data.</li> </ul>"},{"location":"api_reference/#show_errors","title":"<code>show_errors()</code>","text":"<p>Displays all logged errors in a user-friendly format.</p>"},{"location":"api_reference/#has_errors-bool","title":"<code>has_errors() -&gt; bool</code>","text":"<p>Checks if any errors have been logged.</p> <ul> <li>Returns:</li> <li><code>bool</code>: <code>True</code> if there are errors, <code>False</code> otherwise.</li> </ul>"},{"location":"api_reference/#get_ordered_variable_names-liststr","title":"<code>get_ordered_variable_names() -&gt; List[str]</code>","text":"<p>Retrieves the names of ordinal and nominal variables.</p> <ul> <li>Returns:</li> <li><code>List[str]</code>: List of ordered variable names.</li> </ul>"},{"location":"api_reference/#causalpipeconfig","title":"CausalPipeConfig","text":"<p><code>CausalPipeConfig</code> is a Pydantic model that encapsulates all configuration parameters required to set up the CausalPipe pipeline. It leverages enums for various configurable options and includes validations to ensure the integrity of the configuration.</p>"},{"location":"api_reference/#attributes","title":"Attributes","text":"<ul> <li><code>variable_types</code> (<code>VariableTypes</code>): Defines the types of variables (<code>continuous</code>, <code>ordinal</code>, <code>nominal</code>) in the dataset.</li> <li><code>preprocessing_params</code> (<code>DataPreprocessingParams</code>): Parameters for data preprocessing.</li> <li><code>skeleton_method</code> (<code>SkeletonMethod</code>): Configuration for skeleton identification methods.</li> <li><code>BCSLSkeletonMethod</code></li> <li><code>FASSkeletonMethod</code></li> <li><code>orientation_method</code> (<code>OrientationMethod</code>): Configuration for edge orientation methods.</li> <li><code>FCIOrientationMethod</code></li> <li><code>HillClimbingOrientationMethod</code></li> <li><code>causal_effect_methods</code> (<code>Optional[List[CausalEffectMethod]]</code>): List of methods for estimating causal effects. Available classes include <code>PearsonCausalEffectMethod</code>, <code>SpearmanCausalEffectMethod</code>, <code>MICausalEffectMethod</code>, <code>KCICausalEffectMethod</code>, <code>SEMCausalEffectMethod</code>, <code>SEMClimbingCausalEffectMethod</code>, <code>PYSRCausalEffectMethod</code>, and <code>PYSRCausalEffectMethodHillClimbing</code>.</li> <li><code>study_name</code> (<code>str</code>): Unique identifier for the study.</li> <li><code>output_path</code> (<code>str</code>): Directory where results will be saved.</li> <li><code>show_plots</code> (<code>bool</code>): Whether to show plots.</li> <li><code>verbose</code> (<code>bool</code>): Enable verbose logging.</li> </ul>"},{"location":"api_reference/#variabletypes","title":"VariableTypes","text":"<p><code>VariableTypes</code> defines the categorization of variables in your dataset.</p> <ul> <li>Attributes:<ul> <li><code>continuous</code> (<code>List[str]</code>): List of continuous variable names.</li> <li><code>ordinal</code> (<code>List[str]</code>, default <code>[]</code>): List of ordinal variable names.</li> <li><code>nominal</code> (<code>List[str]</code>, default <code>[]</code>): List of nominal variable names.</li> </ul> </li> </ul>"},{"location":"api_reference/#datapreprocessingparams","title":"DataPreprocessingParams","text":"<p><code>DataPreprocessingParams</code> configures how data preprocessing is handled in the pipeline.</p> <ul> <li> <p>Attributes:</p> <ul> <li><code>no_preprocessing</code> (<code>bool</code>, default <code>False</code>): Whether to skip preprocessing.</li> <li><code>handling_missing</code> (<code>HandlingMissingEnum</code>, default <code>HandlingMissingEnum.IMPUTE</code>): Method to handle missing values.</li> <li>Options:<ul> <li><code>\"impute\"</code></li> <li><code>\"drop\"</code></li> <li><code>\"error\"</code></li> </ul> </li> <li><code>cat_to_codes</code> (<code>bool</code>, default <code>True</code>): Whether to convert categorical variables to numeric codes.</li> <li><code>standardize</code> (<code>bool</code>, default <code>True</code>): Whether to standardize continuous variables.</li> <li><code>imputation_method</code> (<code>ImputationMethodEnum</code>, default <code>ImputationMethodEnum.MICE</code>): Method for imputation.</li> <li>Options:<ul> <li><code>\"mice\"</code></li> <li><code>\"simple\"</code></li> </ul> </li> <li><code>use_r_mice</code> (<code>bool</code>, default <code>True</code>): Whether to use R's <code>mice</code> for imputation.</li> <li><code>full_obs_cols</code> (<code>Optional[List[str]]</code>, default <code>None</code>): Columns to keep as fully observed.</li> <li><code>keep_only_correlated_with</code> (<code>Optional[List[str]]</code>, default <code>None</code>): List of target variables. Only features correlated with these targets are kept.</li> <li><code>filter_method</code> (<code>FilterMethodEnum</code>, default <code>FilterMethodEnum.MUTUAL_INFO</code>): Method to filter out features without correlation with the target.</li> <li>Options:<ul> <li><code>\"mutual_info\"</code></li> <li><code>\"pearson\"</code></li> <li><code>\"lasso\"</code></li> </ul> </li> <li><code>filter_threshold</code> (<code>float</code>, default <code>0.1</code>): Threshold for the filter method. Must be between <code>0.0</code> and <code>1.0</code>.</li> <li><code>kwargs</code> (<code>Optional[Dict[str, Any]]</code>, default <code>{}</code>): Additional keyword arguments.</li> </ul> </li> <li> <p>Validations:</p> <ul> <li><code>filter_threshold</code> must be between <code>0.0</code> and <code>1.0</code>.</li> </ul> </li> </ul>"},{"location":"api_reference/#skeletonmethod","title":"SkeletonMethod","text":"<p><code>SkeletonMethod</code> is a base Pydantic model for configuring skeleton identification methods.</p> <ul> <li> <p>Attributes:</p> <ul> <li><code>name</code> (<code>SkeletonMethodNameEnum</code>): Name of the skeleton method.</li> <li>Options:<ul> <li><code>\"BCSL\"</code></li> <li><code>\"FAS\"</code></li> </ul> </li> <li><code>conditional_independence_method</code> (<code>ConditionalIndependenceMethodEnum</code>, default <code>ConditionalIndependenceMethodEnum.FISHERZ</code>): Method for conditional independence testing.</li> <li>Options:<ul> <li><code>\"fisherz\"</code></li> <li><code>\"kci\"</code></li> <li><code>\"d_separation\"</code></li> <li><code>\"gsq\"</code></li> <li><code>\"chisq\"</code></li> <li><code>\"mc_fisherz\"</code></li> <li><code>\"mv_fisherz\"</code></li> </ul> </li> <li><code>alpha</code> (<code>float</code>, default <code>0.05</code>): Significance level for tests. Must be between <code>0.0</code> and <code>1.0</code>.</li> <li><code>params</code> (<code>Optional[Dict[str, Any]]</code>, default <code>{}</code>): Additional parameters.</li> <li><code>bootstrap_resamples</code> (<code>int</code>, default <code>0</code>): Number of bootstrap resamples for skeleton stability estimation. Must be non-negative.</li> <li><code>bootstrap_random_state</code> (<code>Optional[int]</code>, default <code>None</code>): Seed for the skeleton bootstrap resampling procedure.</li> <li><code>bootstrap_edge_threshold</code> (<code>Optional[float]</code>, default <code>None</code>): If set, edges in the FAS graph with bootstrap probability below this threshold are removed. Must be between <code>0.0</code> and <code>1.0</code>.</li> </ul> </li> <li> <p>Validations:</p> <ul> <li><code>alpha</code> must be between <code>0.0</code> and <code>1.0</code>.</li> <li><code>bootstrap_resamples</code> must be non-negative.</li> <li><code>bootstrap_edge_threshold</code> must be between <code>0.0</code> and <code>1.0</code>.</li> </ul> </li> </ul>"},{"location":"api_reference/#bcslskeletonmethod","title":"BCSLSkeletonMethod","text":"<p><code>BCSLSkeletonMethod</code> configures the Bootstrap-based Causal Structure Learning (BCSL) method for skeleton identification.</p> <ul> <li> <p>Inherits From: <code>SkeletonMethod</code></p> </li> <li> <p>Attributes:</p> <ul> <li><code>name</code> (<code>SkeletonMethodNameEnum</code>, default <code>SkeletonMethodNameEnum.BCSL</code>): Name of the skeleton method.</li> <li><code>num_bootstrap_samples</code> (<code>int</code>, default <code>100</code>): Number of bootstrap samples. Must be positive.</li> <li><code>multiple_comparison_correction</code> (<code>Optional[MultipleComparisonCorrectionEnum]</code>, default <code>None</code>): Method for multiple comparison correction.</li> <li>Options:<ul> <li><code>\"fdr\"</code></li> <li><code>\"bonferroni\"</code></li> </ul> </li> <li><code>bootstrap_all_edges</code> (<code>bool</code>, default <code>True</code>): Whether to bootstrap all edges.</li> <li><code>use_aee_alpha</code> (<code>float</code>, default <code>0.05</code>): Alpha level for AEE. Must be between <code>0.0</code> and <code>1.0</code>.</li> <li><code>max_k</code> (<code>int</code>, default <code>3</code>): Maximum conditioning set size. Must be non-negative.</li> </ul> </li> <li> <p>Validations:</p> <ul> <li><code>num_bootstrap_samples</code> must be positive.</li> <li><code>use_aee_alpha</code> must be between <code>0.0</code> and <code>1.0</code>.</li> <li><code>alpha</code> (inherited) must be between <code>0.0</code> and <code>1.0</code>.</li> <li><code>max_k</code> must be non-negative.</li> </ul> </li> </ul>"},{"location":"api_reference/#fasskeletonmethod","title":"FASSkeletonMethod","text":"<p><code>FASSkeletonMethod</code> configures the Fast Adjacency Search (FAS) method for skeleton identification.</p> <ul> <li> <p>Inherits From: <code>SkeletonMethod</code></p> </li> <li> <p>Attributes:</p> <ul> <li><code>name</code> (<code>SkeletonMethodNameEnum</code>, default <code>SkeletonMethodNameEnum.FAS</code>): Name of the skeleton method.</li> <li><code>depth</code> (<code>int</code>, default <code>3</code>): Depth parameter for FAS. Must be non-negative.</li> <li><code>knowledge</code> (<code>Optional[BackgroundKnowledge]</code>, default <code>None</code>): Background knowledge for FAS.</li> </ul> </li> <li> <p>Validations:</p> <ul> <li><code>depth</code> must be non-negative.</li> </ul> </li> <li> <p>Configuration:</p> <ul> <li><code>arbitrary_types_allowed = True</code> (Allows non-Pydantic types like <code>BackgroundKnowledge</code>)</li> </ul> </li> </ul>"},{"location":"api_reference/#orientationmethod","title":"OrientationMethod","text":"<p><code>OrientationMethod</code> is a base Pydantic model for configuring edge orientation methods.</p> <ul> <li>Attributes:<ul> <li><code>name</code> (<code>OrientationMethodNameEnum</code>): Name of the orientation method.</li> <li>Options:<ul> <li><code>\"FCI\"</code></li> <li><code>\"Hill Climbing\"</code></li> </ul> </li> <li><code>conditional_independence_method</code> (<code>ConditionalIndependenceMethodEnum</code>, default <code>ConditionalIndependenceMethodEnum.FISHERZ</code>): Method for conditional independence testing.</li> <li>Options:<ul> <li><code>\"fisherz\"</code></li> <li><code>\"kci\"</code></li> <li><code>\"d_separation\"</code></li> <li><code>\"gsq\"</code></li> <li><code>\"chisq\"</code></li> <li><code>\"mc_fisherz\"</code></li> <li><code>\"mv_fisherz\"</code></li> </ul> </li> <li><code>bootstrap_resamples</code> (<code>int</code>, default <code>0</code>): Number of bootstrap resamples to estimate edge orientation stability. Must be non-negative.</li> <li><code>bootstrap_random_state</code> (<code>Optional[int]</code>, default <code>None</code>): Seed for the orientation bootstrap resampling procedure.</li> </ul> </li> </ul>"},{"location":"api_reference/#fciorientationmethod","title":"FCIOrientationMethod","text":"<p><code>FCIOrientationMethod</code> configures the Fast Causal Inference (FCI) method for edge orientation.</p> <ul> <li> <p>Inherits From: <code>OrientationMethod</code></p> </li> <li> <p>Attributes:</p> <ul> <li><code>name</code> (<code>OrientationMethodNameEnum</code>, default <code>OrientationMethodNameEnum.FCI</code>): Name of the orientation method.</li> <li><code>background_knowledge</code> (<code>Optional[BackgroundKnowledge]</code>, default <code>None</code>): Background knowledge for FCI.</li> <li><code>alpha</code> (<code>float</code>, default <code>0.05</code>): Significance level for tests. Must be between <code>0.0</code> and <code>1.0</code>.</li> <li><code>max_path_length</code> (<code>int</code>, default <code>3</code>): Maximum path length for FCI. Must be non-negative.</li> </ul> </li> <li> <p>Validations:</p> <ul> <li><code>alpha</code> must be between <code>0.0</code> and <code>1.0</code>.</li> <li><code>max_path_length</code> must be non-negative.</li> </ul> </li> <li> <p>Configuration:</p> <ul> <li><code>arbitrary_types_allowed = True</code> (Allows non-Pydantic types like <code>BackgroundKnowledge</code>)</li> </ul> </li> </ul>"},{"location":"api_reference/#hillclimbingorientationmethod","title":"HillClimbingOrientationMethod","text":"<p><code>HillClimbingOrientationMethod</code> configures the Hill Climbing method for edge orientation.</p> <ul> <li> <p>Inherits From: <code>OrientationMethod</code></p> </li> <li> <p>Attributes:</p> <ul> <li><code>name</code> (<code>OrientationMethodNameEnum</code>, default <code>OrientationMethodNameEnum.HILL_CLIMBING</code>): Name of the orientation method.</li> <li><code>max_k</code> (<code>int</code>, default <code>3</code>): Maximum conditioning set size. Must be non-negative.</li> <li><code>multiple_comparison_correction</code> (<code>Optional[MultipleComparisonCorrectionEnum]</code>, default <code>None</code>): Method for multiple comparison correction.</li> <li>Options:<ul> <li><code>\"fdr\"</code></li> <li><code>\"bonferroni\"</code></li> </ul> </li> </ul> </li> <li> <p>Validations:</p> <ul> <li><code>max_k</code> must be non-negative.</li> </ul> </li> </ul>"},{"location":"api_reference/#causaleffectmethod","title":"CausalEffectMethod","text":"<p><code>CausalEffectMethod</code> is the base configuration for estimating causal effects. Users may instantiate this class directly with a name and an optional dictionary of parameters. When used this way, CausalPipe automatically converts the instance into one of the specialised subclasses below.</p> <ul> <li>Attributes:<ul> <li><code>name</code> (<code>CausalEffectMethodNameEnum</code>, default <code>CausalEffectMethodNameEnum.PEARSON</code>): Name of the causal effect method.</li> <li><code>directed</code> (<code>bool</code>, default <code>True</code>): Whether to use the directed graph.</li> <li><code>params</code> (<code>Optional[Dict[str, Any]]</code>, default <code>{}</code>): Legacy parameter dictionary.</li> </ul> </li> </ul>"},{"location":"api_reference/#pearsoncausaleffectmethod","title":"PearsonCausalEffectMethod","text":"<p>Partial Pearson correlation. No additional parameters besides <code>directed</code>.</p>"},{"location":"api_reference/#spearmancausaleffectmethod","title":"SpearmanCausalEffectMethod","text":"<p>Partial Spearman correlation. No additional parameters besides <code>directed</code>.</p>"},{"location":"api_reference/#micausaleffectmethod","title":"MICausalEffectMethod","text":"<p>Conditional Mutual Information. No additional parameters besides <code>directed</code>.</p>"},{"location":"api_reference/#kcicausaleffectmethod","title":"KCICausalEffectMethod","text":"<p>Kernel Conditional Independence. No additional parameters besides <code>directed</code>.</p>"},{"location":"api_reference/#semcausaleffectmethod","title":"SEMCausalEffectMethod","text":"<p>Structural Equation Modeling.</p> <ul> <li>Parameters:<ul> <li><code>estimator</code> (<code>Optional[str]</code>, default <code>None</code>): Estimator passed to the SEM fitting routine. If <code>None</code>, an appropriate default is selected.</li> </ul> </li> </ul>"},{"location":"api_reference/#semclimbingcausaleffectmethod","title":"SEMClimbingCausalEffectMethod","text":"<p>Structural Equation Modeling with Hill Climbing search.</p> <ul> <li>Parameters:<ul> <li><code>estimator</code> (<code>Optional[str]</code>, default <code>None</code>)</li> <li><code>respect_pag</code> (<code>bool</code>, default <code>True</code>)</li> <li><code>finalize_with_resid_covariances</code> (<code>bool</code>, default <code>False</code>)</li> <li><code>max_iter</code> (<code>int</code>, default <code>100</code>)</li> <li><code>mi_cutoff</code> (<code>float</code>, default <code>10.0</code>)</li> <li><code>sepc_cutoff</code> (<code>float</code>, default <code>0.10</code>)</li> <li><code>max_add</code> (<code>int</code>, default <code>5</code>)</li> <li><code>delta_stop</code> (<code>float</code>, default <code>0.003</code>)</li> <li><code>whitelist_pairs</code> (<code>Optional[List[Tuple[str, str]]]</code>, default <code>None</code>)</li> <li><code>forbid_pairs</code> (<code>Optional[List[Tuple[str, str]]]</code>, default <code>None</code>)</li> <li><code>same_occasion_regex</code> (<code>Optional[str]</code>, default <code>None</code>)</li> </ul> </li> </ul>"},{"location":"api_reference/#pysrcausaleffectmethod","title":"PYSRCausalEffectMethod","text":"<p>Symbolic regression using PySR.</p> <ul> <li>Parameters:<ul> <li><code>noise_kind</code> (<code>str</code>, default <code>\"gaussian\"</code>)</li> <li><code>alpha</code> (<code>float</code>, default <code>0.3</code>)</li> <li><code>tol</code> (<code>float</code>, default <code>1e-6</code>)</li> <li><code>max_iter</code> (<code>int</code>, default <code>500</code>)</li> <li><code>restarts</code> (<code>int</code>, default <code>2</code>)</li> <li><code>standardized_init</code> (<code>bool</code>, default <code>False</code>)</li> <li><code>hc_orient_undirected_edges</code> (<code>bool</code>, default <code>False</code>)</li> <li><code>pysr_params</code> (<code>Dict[str, Any]</code>, default <code>{}</code>)</li> </ul> </li> </ul>"},{"location":"api_reference/#pysrcausaleffectmethodhillclimbing","title":"PYSRCausalEffectMethodHillClimbing","text":"<p>Symbolic regression using PySR with additional hill-climbing search to orient undirected edges.</p> <ul> <li>Parameters:<ul> <li><code>hc_orient_undirected_edges</code> (<code>bool</code>, default <code>True</code>)</li> <li><code>hc_max_iter</code> (<code>int</code>, default <code>100</code>)</li> <li><code>estimator</code> (<code>PySREstimatorEnum</code>, default <code>PySREstimatorEnum.MMDSQUARED</code>)</li> <li><code>respect_pag</code> (<code>bool</code>, default <code>True</code>)</li> <li><code>pysr_params</code> (<code>Dict[str, Any]</code>, default <code>{}</code>)</li> </ul> </li> </ul>"},{"location":"api_reference/#semscore","title":"SEMScore","text":"<p><code>SEMScore</code> is a class used to score graph structures based on Structural Equation Modeling (SEM) fits. It integrates with CausalPipe to evaluate the quality of causal graphs.</p>"},{"location":"api_reference/#initialization_1","title":"Initialization","text":"<pre><code>SEMScore(\n    data: pd.DataFrame,\n    var_names: Optional[Dict[str, str]] = None,\n    estimator: str = \"MLR\",\n    return_metrics: bool = False,\n    ordered: Optional[List[str]] = None,\n)\n</code></pre> <ul> <li>Parameters:</li> <li><code>data</code> (<code>pd.DataFrame</code>): The dataset used for SEM fitting.</li> <li><code>var_names</code> (<code>Optional[Dict[str, str]]</code>, default <code>None</code>): A dictionary mapping current factor names to meaningful names. Example: <code>{'Academic': 'Academic_Ability', 'Arts': 'Artistic_Skills'}</code>.</li> <li><code>estimator</code> (<code>str</code>, default <code>\"MLR\"</code>): The estimator to use for fitting the SEM model. Options include <code>\"MLM\"</code>, <code>\"MLR\"</code>, <code>\"ULS\"</code>, <code>\"WLSMV\"</code>, etc. <code>\"bayesian\"</code> is not yet implemented.</li> <li><code>return_metrics</code> (<code>bool</code>, default <code>False</code>): Whether to return additional fit metrics in the output.</li> <li><code>ordered</code> (<code>Optional[List[str]]</code>, default <code>None</code>): A list of variable names that are ordered (ordinal variables). Currently not implemented and will be ignored with a warning.</li> </ul>"},{"location":"api_reference/#methods_1","title":"Methods","text":""},{"location":"api_reference/#__call__general_graph-generalgraph-compared_to_graph-optionalgeneralgraph-none-dictstr-any","title":"<code>__call__(general_graph: GeneralGraph, compared_to_graph: Optional[GeneralGraph] = None) -&gt; Dict[str, Any]</code>","text":"<p>Calculates the score of the given graph based on BIC from SEM fitting.</p> <ul> <li>Parameters:</li> <li><code>general_graph</code> (<code>GeneralGraph</code>): The graph to score.</li> <li> <p><code>compared_to_graph</code> (<code>Optional[GeneralGraph]</code>, default <code>None</code>): The graph to compare the given graph against.</p> </li> <li> <p>Returns:</p> </li> <li><code>Dict[str, Any]</code>: A dictionary containing the score and additional SEM fitting results.</li> </ul>"},{"location":"api_reference/#exhaustive_resultsgeneral_graph-generalgraph-compared_to_graph-optionalgeneralgraph-none-dictstr-any","title":"<code>exhaustive_results(general_graph: GeneralGraph, compared_to_graph: Optional[GeneralGraph] = None) -&gt; Dict[str, Any]</code>","text":"<p>Fits an SEM model for the given graph and returns the results.</p> <ul> <li>Parameters:</li> <li><code>general_graph</code> (<code>GeneralGraph</code>): The graph structure to fit.</li> <li> <p><code>compared_to_graph</code> (<code>Optional[GeneralGraph]</code>, default <code>None</code>): The graph structure to compare the given graph against.</p> </li> <li> <p>Returns:</p> </li> <li><code>Dict[str, Any]</code>: A dictionary containing the SEM fitting results.</li> </ul>"},{"location":"api_reference/#functions","title":"Functions","text":""},{"location":"api_reference/#fit_sem_lavaan","title":"fit_sem_lavaan","text":"<p><code>fit_sem_lavaan</code> fits a Structural Equation Model (SEM) using the specified model string and returns comprehensive results. It leverages R's <code>lavaan</code> package via <code>rpy2</code> for SEM fitting.</p> <pre><code>fit_sem_lavaan(\n    data: pd.DataFrame,\n    model_1_string: str,\n    var_names: Optional[Dict[str, str]] = None,\n    estimator: str = \"MLM\",\n    model_2_string: Optional[str] = None,\n    ordered: Optional[List[str]] = None,\n) -&gt; Dict[str, Any]\n</code></pre> <ul> <li> <p>Parameters:</p> <ul> <li><code>data</code> (<code>pd.DataFrame</code>): The dataset including all variables needed for the SEM.</li> <li><code>model_1_string</code> (<code>str</code>): The model specification string for SEM in lavaan syntax.</li> <li><code>var_names</code> (<code>Optional[Dict[str, str]]</code>, default <code>None</code>): A dictionary mapping current factor names to meaningful names. Example: <code>{'Academic': 'Academic_Ability', 'Arts': 'Artistic_Skills'}</code>.</li> <li><code>estimator</code> (<code>str</code>, default <code>\"MLM\"</code>): The estimator to use for fitting the SEM model. Options include <code>\"MLM\"</code>, <code>\"MLR\"</code>, <code>\"ULS\"</code>, <code>\"WLSMV\"</code>.</li> <li><code>model_2_string</code> (<code>Optional[str]</code>, default <code>None</code>): The model specification string for the second SEM model to compare.</li> <li><code>ordered</code> (<code>Optional[List[str]]</code>, default <code>None</code>): A list of variable names that are ordered (ordinal variables).</li> </ul> </li> <li> <p>Returns:</p> <ul> <li><code>Dict[str, Any]</code>: A dictionary containing:<ul> <li><code>'model_string'</code>: The SEM model specification string.</li> <li><code>'fit_summary'</code>: The SEM fit summary as a string.</li> <li><code>'fit_measures'</code>: Selected fit indices as a dictionary.</li> <li><code>'measurement_model'</code>: Parameter estimates for the measurement model.</li> <li><code>'structural_model'</code>: Parameter estimates for the structural model.</li> <li><code>'residual_covariances'</code>: Residual covariances.</li> <li><code>'factor_scores'</code>: Factor scores for each participant.</li> <li><code>'r2'</code>: R\u00b2 values for endogenous variables.</li> <li><code>'log_likelihood'</code>: The total log-likelihood of the model (if available).</li> <li><code>'log_likelihoods'</code>: Per-sample log-likelihoods (if available).</li> <li><code>'npar'</code>: Number of parameters estimated in the model.</li> <li><code>'n_samples'</code>: Number of observations in the data.</li> <li><code>'comparison_results'</code>: Model comparison results (if <code>model_2_string</code> is provided).</li> <li><code>'is_better_model'</code>: Indicator of which model is better.</li> <li><code>'model_2_string'</code>: The second model specification string (if provided).</li> </ul> </li> </ul> </li> <li> <p>Usage Example:</p> </li> </ul> <p>```python   import pandas as pd</p> <p>data = pd.read_csv(\"your_data.csv\")   model_1 = \"\"\"   Academic =~ Math + Science + Literature   Sports =~ Football + Basketball + Tennis   Academic ~ Sports   \"\"\"</p> <p>results = fit_sem_lavaan(       data=data,       model_1_string=model_1,       estimator=\"MLM\",       ordered=[\"Math\", \"Science\", \"Literature\", \"Football\", \"Basketball\", \"Tennis\"]   )</p> <p>print(results[\"fit_summary\"])   ```</p>"},{"location":"api_reference/#search_best_graph_climber","title":"search_best_graph_climber","text":"<p><code>search_best_graph_climber</code> searches for the best graph structure using hill-climbing based on SEM fit.</p> <pre><code>search_best_graph_climber(\n    data: pd.DataFrame,\n    initial_graph: GeneralGraph,\n    node_names: Optional[List[str]] = None,\n    max_iter: int = 1000,\n    estimator: str = \"MLM\",\n    finalize_with_resid_covariances: bool = False,\n    mi_cutoff: float = 10.0,\n    sepc_cutoff: float = 0.10,\n    max_add: int = 5,\n    delta_stop: float = 0.003,\n    whitelist_pairs: Optional[pd.DataFrame] = None,\n    forbid_pairs: Optional[pd.DataFrame] = None,\n    same_occasion_regex: Optional[str] = None,\n    ordered: Optional[List[str]] = None,\n    *,\n    respect_pag: bool = False,\n    bootstrap_resamples: int = 0,\n    bootstrap_random_state: Optional[int] = None,\n    n_jobs: Optional[int] = 1,\n) -&gt; Tuple[GeneralGraph, Dict[str, Any]]\n</code></pre> <ul> <li> <p>Parameters:</p> <ul> <li><code>data</code> (<code>pd.DataFrame</code>): The dataset used for SEM fitting.</li> <li><code>initial_graph</code> (<code>GeneralGraph</code>): The initial graph structure to start the search.</li> <li><code>node_names</code> (<code>Optional[List[str]]</code>, default <code>None</code>): A list of variable names in the dataset.</li> <li><code>max_iter</code> (<code>int</code>, default <code>1000</code>): The maximum number of iterations for the hill-climbing search.</li> <li><code>estimator</code> (<code>str</code>, default <code>\"MLM\"</code>): The estimator to use for fitting the SEM model. Options include <code>\"MLM\"</code>, <code>\"MLR\"</code>, <code>\"ULS\"</code>, <code>\"WLSMV\"</code>.</li> <li><code>finalize_with_resid_covariances</code> (<code>bool</code>, default <code>False</code>): If <code>True</code>, run a post-hoc stepwise residual covariance augmentation.</li> <li><code>mi_cutoff</code> (<code>float</code>, default <code>10.0</code>): Minimum modification index threshold for considering a covariance.</li> <li><code>sepc_cutoff</code> (<code>float</code>, default <code>0.10</code>): Minimum absolute <code>sepc.all</code> threshold.</li> <li><code>max_add</code> (<code>int</code>, default <code>5</code>): Maximum number of covariances to add.</li> <li><code>delta_stop</code> (<code>float</code>, default <code>0.003</code>): Minimum improvement required in fit indices to continue.</li> <li><code>whitelist_pairs</code> (<code>Optional[pd.DataFrame]</code>, default <code>None</code>): Optional whitelist of pairs (<code>lhs</code>, <code>rhs</code>).</li> <li><code>forbid_pairs</code> (<code>Optional[pd.DataFrame]</code>, default <code>None</code>): Optional blocklist of pairs.</li> <li><code>same_occasion_regex</code> (<code>Optional[str]</code>, default <code>None</code>): Regex enforcing same-occasion pairs unless whitelisted.</li> <li><code>ordered</code> (<code>Optional[List[str]]</code>, default <code>None</code>): Ordered categorical variables in the data.</li> <li><code>respect_pag</code> (<code>bool</code>, default <code>False</code>): When <code>True</code>, the search preserves PAG marks (no change to \u2194, \u2192, \u2014; only resolves circle endpoints consistent with PAG semantics).</li> <li><code>bootstrap_resamples</code> (<code>int</code>, default <code>0</code>): If greater than <code>0</code>, run the SEM hill climber on bootstrap resamples to estimate orientation probabilities after hill climbing.</li> <li><code>bootstrap_random_state</code> (<code>Optional[int]</code>, default <code>None</code>): Seed for the hill-climb bootstrap resampling procedure.</li> <li><code>n_jobs</code> (<code>Optional[int]</code>, default <code>1</code>): Number of worker processes to use for bootstrapped hill climbing.</li> </ul> </li> <li> <p>Returns:</p> <ul> <li><code>Tuple[GeneralGraph, Dict[str, Any]]</code>: A tuple containing:<ul> <li><code>best_graph</code> (<code>GeneralGraph</code>): The graph structure with the best SEM fit.</li> <li><code>best_score</code> (<code>Dict[str, Any]</code>): SEM results. When residual covariance augmentation is enabled, this dictionary also includes <code>without_added_covariance_score</code> (the pre-augmentation score) and <code>resid_cov_aug</code> (details of the augmentation step). If hill-climb bootstrapping is requested, <code>hc_edge_orientation_probabilities</code> contains orientation probabilities after hill climbing.</li> </ul> </li> </ul> </li> <li> <p>Usage Example:</p> </li> </ul> <p>```python   import pandas as pd   from causallearn.graph.GeneralGraph import GeneralGraph</p> <p>data = pd.read_csv(\"your_data.csv\")   initial_graph = GeneralGraph(nodes=[0, 1, 2], edges={})</p> <p>best_graph, best_score = search_best_graph_climber(       data=data,       initial_graph=initial_graph,       max_iter=500,       estimator=\"MLR\",       finalize_with_resid_covariances=True,   )</p> <p>print(best_graph)   print(best_score[\"fit_measures\"])   ```</p>"},{"location":"api_reference/#updated-configuration-classes","title":"Updated Configuration Classes","text":"<p>Below are the updated Pydantic classes used for configuring the CausalPipe pipeline. These classes incorporate enums for various configurable options and include validations to ensure configuration integrity.</p>"},{"location":"api_reference/#enumerations","title":"Enumerations","text":"<pre><code>from enum import Enum\n\nclass HandlingMissingEnum(str, Enum):\n    IMPUTE = \"impute\"\n    DROP = \"drop\"\n    ERROR = \"error\"\n\nclass ImputationMethodEnum(str, Enum):\n    MICE = \"mice\"\n    SIMPLE = \"simple\"\n\nclass FilterMethodEnum(str, Enum):\n    MUTUAL_INFO = \"mutual_info\"\n    PEARSON = \"pearson\"\n    LASSO = \"lasso\"\n\nclass SkeletonMethodNameEnum(str, Enum):\n    BCSL = \"BCSL\"\n    FAS = \"FAS\"\n\nclass ConditionalIndependenceMethodEnum(str, Enum):\n    FISHERZ = \"fisherz\"\n    KCI = \"kci\"\n    D_SEPARATION = \"d_separation\"\n    GSQ = \"gsq\"\n    CHISQ = \"chisq\"\n    MC_FISHERZ = \"mc_fisherz\"\n    MV_FISHERZ = \"mv_fisherz\"\n\nclass MultipleComparisonCorrectionEnum(str, Enum):\n    FDR = \"fdr\"\n    BONFERRONI = \"bonferroni\"\n\nclass OrientationMethodNameEnum(str, Enum):\n    FCI = \"FCI\"\n    HILL_CLIMBING = \"Hill Climbing\"\n\nclass CausalEffectMethodNameEnum(str, Enum):\n    PEARSON = \"pearson\"\n    SPEARMAN = \"spearman\"\n    MI = \"mi\"\n    KCI = \"kci\"\n    SEM = \"sem\"\n    SEM_CLIMBING = \"sem-climbing\"\n</code></pre>"},{"location":"api_reference/#pydantic-models-with-validations","title":"Pydantic Models with Validations","text":""},{"location":"api_reference/#variabletypes_1","title":"VariableTypes","text":"<pre><code>from pydantic import BaseModel, Field, field_validator\nfrom typing import List\n\nclass VariableTypes(BaseModel):\n    \"\"\"\n    Define variable types for the dataset.\n    \"\"\"\n\n    continuous: List[str]\n    ordinal: List[str] = Field(default_factory=list)\n    nominal: List[str] = Field(default_factory=list)\n</code></pre>"},{"location":"api_reference/#datapreprocessingparams_1","title":"DataPreprocessingParams","text":"<pre><code>from pydantic import BaseModel, Field, field_validator\nfrom typing import List, Optional, Dict, Any\n\nclass DataPreprocessingParams(BaseModel):\n    \"\"\"\n    Parameters for data preprocessing.\n\n    Attributes:\n        no_preprocessing (bool): True if no preprocessing is required.\n        handling_missing (HandlingMissingEnum): Method to handle missing values.\n        cat_to_codes (bool): True if categorical variables should be converted to codes.\n        standardize (bool): True if the data should be standardized.\n        imputation_method (ImputationMethodEnum): Method to impute missing values.\n        use_r_mice (bool): True if R MICE should be used for imputation.\n        full_obs_cols (Optional[List[str]]): Columns with full observations - row is dropped if any missing values.\n        keep_only_correlated_with (Optional[List[str]]): List of target variables. Only features correlated with these targets are kept.\n        filter_method (FilterMethodEnum): Method to filter out features without correlation with the target.\n        filter_threshold (float): Threshold for the filter method.\n        kwargs (Optional[Dict[str, Any]]): Additional parameters for the preprocessing.\n    \"\"\"\n\n    no_preprocessing: bool = False\n    handling_missing: HandlingMissingEnum = HandlingMissingEnum.IMPUTE\n    cat_to_codes: bool = True\n    standardize: bool = True\n\n    # Imputation parameters\n    imputation_method: ImputationMethodEnum = ImputationMethodEnum.MICE\n    use_r_mice: bool = True\n    full_obs_cols: Optional[List[str]] = None\n\n    # Filter out features without correlation with the target\n    keep_only_correlated_with: Optional[List[str]] = None\n    filter_method: FilterMethodEnum = FilterMethodEnum.MUTUAL_INFO\n    filter_threshold: float = 0.1\n\n    kwargs: Optional[Dict[str, Any]] = Field(default_factory=dict)\n\n    # Validation for filter_threshold\n    @field_validator(\"filter_threshold\")\n    @classmethod\n    def check_filter_threshold(cls, v):\n        if not (0.0 &lt;= v &lt;= 1.0):\n            raise ValueError(\"filter_threshold must be between 0.0 and 1.0\")\n        return v\n\n    class Config:\n        validate_assignment = True\n</code></pre>"},{"location":"api_reference/#skeletonmethod_1","title":"SkeletonMethod","text":"<pre><code>from pydantic import BaseModel, Field, field_validator\nfrom typing import Optional, Dict, Any\n\nclass SkeletonMethod(BaseModel):\n    \"\"\"\n    Configuration for skeleton identification.\n    \"\"\"\n\n    name: SkeletonMethodNameEnum\n    conditional_independence_method: ConditionalIndependenceMethodEnum = (\n        ConditionalIndependenceMethodEnum.FISHERZ\n    )\n    alpha: float = 0.05\n    params: Optional[Dict[str, Any]] = Field(default_factory=dict)\n    bootstrap_resamples: int = 0\n    bootstrap_random_state: Optional[int] = None\n\n    # Validation for alpha\n    @field_validator(\"alpha\")\n    @classmethod\n    def check_alpha(cls, v):\n        if not (0.0 &lt; v &lt; 1.0):\n            raise ValueError(\"alpha must be between 0.0 and 1.0\")\n        return v\n\n    @field_validator(\"bootstrap_resamples\")\n    @classmethod\n    def check_bootstrap_resamples(cls, v):\n        if v &lt; 0:\n            raise ValueError(\"bootstrap_resamples must be non-negative\")\n        return v\n\n    class Config:\n        validate_assignment = True\n</code></pre>"},{"location":"api_reference/#bcslskeletonmethod_1","title":"BCSLSkeletonMethod","text":"<pre><code>from pydantic import BaseModel, Field, field_validator\nfrom typing import Optional, Dict, Any\n\nclass BCSLSkeletonMethod(SkeletonMethod):\n    \"\"\"\n    Configuration for BCSL skeleton identification.\n    \"\"\"\n\n    name: SkeletonMethodNameEnum = SkeletonMethodNameEnum.BCSL\n    num_bootstrap_samples: int = 100\n    multiple_comparison_correction: Optional[MultipleComparisonCorrectionEnum] = None\n    bootstrap_all_edges: bool = True\n    use_aee_alpha: float = 0.05\n    max_k: int = 3\n\n    # Validation for num_bootstrap_samples\n    @field_validator(\"num_bootstrap_samples\")\n    @classmethod\n    def check_num_bootstrap_samples(cls, v):\n        if v &lt;= 0:\n            raise ValueError(\"num_bootstrap_samples must be positive\")\n        return v\n\n    # Validation for use_aee_alpha and alpha\n    @field_validator(\"use_aee_alpha\", \"alpha\", mode=\"before\")\n    @classmethod\n    def check_alpha_values(cls, v):\n        if not (0.0 &lt; v &lt; 1.0):\n            raise ValueError(\"alpha values must be between 0.0 and 1.0\")\n        return v\n\n    # Validation for max_k\n    @field_validator(\"max_k\")\n    @classmethod\n    def check_max_k(cls, v):\n        if v &lt; 0:\n            raise ValueError(\"max_k must be non-negative\")\n        return v\n</code></pre>"},{"location":"api_reference/#fasskeletonmethod_1","title":"FASSkeletonMethod","text":"<pre><code>from pydantic import BaseModel, Field, field_validator\nfrom typing import Optional\nfrom causallearn.utils.PCUtils.BackgroundKnowledge import BackgroundKnowledge\n\nclass FASSkeletonMethod(SkeletonMethod):\n    \"\"\"\n    Configuration for FAS skeleton identification.\n    \"\"\"\n\n    name: SkeletonMethodNameEnum = SkeletonMethodNameEnum.FAS\n    depth: int = 3\n    knowledge: Optional[BackgroundKnowledge] = None\n\n    # Validation for depth\n    @field_validator(\"depth\")\n    @classmethod\n    def check_depth(cls, v):\n        if v &lt; 0:\n            raise ValueError(\"depth must be non-negative\")\n        return v\n\n    class Config:\n        arbitrary_types_allowed = True  # Allows non-Pydantic types like BackgroundKnowledge\n</code></pre>"},{"location":"api_reference/#orientationmethod_1","title":"OrientationMethod","text":"<pre><code>from pydantic import BaseModel, Field\nfrom typing import Optional, Dict, Any\n\nclass OrientationMethod(BaseModel):\n    \"\"\"\n    Configuration for edge orientation.\n    \"\"\"\n\n    name: OrientationMethodNameEnum\n    conditional_independence_method: ConditionalIndependenceMethodEnum = (\n        ConditionalIndependenceMethodEnum.FISHERZ\n    )\n    bootstrap_resamples: int = 0\n    bootstrap_random_state: Optional[int] = None\n\n    class Config:\n        validate_assignment = True\n\n    @field_validator(\"bootstrap_resamples\")\n    @classmethod\n    def check_bootstrap_resamples(cls, v):\n        if v &lt; 0:\n            raise ValueError(\"bootstrap_resamples must be non-negative\")\n        return v\n</code></pre>"},{"location":"api_reference/#fciorientationmethod_1","title":"FCIOrientationMethod","text":"<pre><code>from pydantic import BaseModel, Field, field_validator\nfrom typing import Optional\nfrom causallearn.utils.PCUtils.BackgroundKnowledge import BackgroundKnowledge\n\nclass FCIOrientationMethod(OrientationMethod):\n    \"\"\"\n    Configuration for FCI orientation method.\n    \"\"\"\n\n    name: OrientationMethodNameEnum = OrientationMethodNameEnum.FCI\n    background_knowledge: Optional[BackgroundKnowledge] = None\n    alpha: float = 0.05\n    max_path_length: int = 3\n\n    # Validation for alpha\n    @field_validator(\"alpha\")\n    @classmethod\n    def check_alpha(cls, v):\n        if not (0.0 &lt; v &lt; 1.0):\n            raise ValueError(\"alpha must be between 0.0 and 1.0\")\n        return v\n\n    # Validation for max_path_length\n    @field_validator(\"max_path_length\")\n    @classmethod\n    def check_max_path_length(cls, v):\n        if v &lt; 0:\n            raise ValueError(\"max_path_length must be non-negative\")\n        return v\n\n    class Config:\n        arbitrary_types_allowed = True  # Allows non-Pydantic types like BackgroundKnowledge\n</code></pre>"},{"location":"api_reference/#hillclimbingorientationmethod_1","title":"HillClimbingOrientationMethod","text":"<pre><code>from pydantic import BaseModel, Field, field_validator\nfrom typing import Optional, Dict, Any\n\nclass HillClimbingOrientationMethod(OrientationMethod):\n    \"\"\"\n    Configuration for Hill Climbing orientation method.\n    \"\"\"\n\n    name: OrientationMethodNameEnum = OrientationMethodNameEnum.HILL_CLIMBING\n    max_k: int = 3\n    multiple_comparison_correction: Optional[MultipleComparisonCorrectionEnum] = None\n\n    # Validation for max_k\n    @field_validator(\"max_k\")\n    @classmethod\n    def check_max_k(cls, v):\n        if v &lt; 0:\n            raise ValueError(\"max_k must be non-negative\")\n        return v\n</code></pre>"},{"location":"api_reference/#causaleffectmethod_1","title":"CausalEffectMethod","text":"<pre><code>from pydantic import BaseModel, Field\nfrom typing import Optional, Dict, Any\n\nclass CausalEffectMethod(BaseModel):\n    \"\"\"\n    Configuration for causal effect estimation methods.\n\n    Attributes:\n        name (CausalEffectMethodNameEnum): Name of the method.\n        directed (bool): True if the method starts from the directed graph,\n                        False if it will use the undirected graph (Markov Blanket / General Skeleton).\n        params (Optional[Dict[str, Any]]): Additional parameters for the method.\n            - For `'pysr'`, accepts ``hc_orient_undirected_edges`` (`bool`, default\n              ``True``) to attempt hill-climbing orientation of undirected edges\n              before fitting PySR; when ``False`` undirected neighbors are\n              treated as parents.\n    \"\"\"\n\n    name: CausalEffectMethodNameEnum = CausalEffectMethodNameEnum.PEARSON\n    directed: bool = True\n    params: Optional[Dict[str, Any]] = Field(default_factory=dict)\n</code></pre>"},{"location":"api_reference/#causalpipeconfig_1","title":"CausalPipeConfig","text":"<pre><code>from pydantic import BaseModel, Field\nfrom typing import List, Optional\nimport uuid\n\nclass CausalPipeConfig(BaseModel):\n    \"\"\"\n    Comprehensive configuration for CausalPipe.\n\n    Attributes:\n        variable_types (VariableTypes): Definitions of variable types.\n        preprocessing_params (DataPreprocessingParams): Data preprocessing parameters.\n        skeleton_method (SkeletonMethod): Configuration for skeleton identification.\n        orientation_method (OrientationMethod): Configuration for edge orientation.\n        causal_effect_methods (Optional[List[CausalEffectMethod]]): List of causal effect estimation methods.\n        study_name (str): Unique identifier for the study.\n        output_path (str): Path to save the results.\n        show_plots (bool): Whether to display plots.\n        verbose (bool): Whether to enable verbose logging.\n    \"\"\"\n\n    variable_types: VariableTypes = Field(\n        default_factory=lambda: VariableTypes(continuous=[], ordinal=[], nominal=[])\n    )\n    preprocessing_params: DataPreprocessingParams = Field(\n        default_factory=DataPreprocessingParams\n    )\n    skeleton_method: SkeletonMethod = Field(default_factory=FASSkeletonMethod)\n    orientation_method: OrientationMethod = Field(default_factory=FCIOrientationMethod)\n    causal_effect_methods: Optional[List[CausalEffectMethod]] = Field(\n        default_factory=lambda: [CausalEffectMethod()]\n    )\n    study_name: str = Field(default_factory=lambda: f\"study_{uuid.uuid4()}\")\n    output_path: str = \"./output/causal_toolkit_results\"\n    show_plots: bool = True\n    verbose: bool = False\n\n    class Config:\n        arbitrary_types_allowed = True\n        validate_assignment = True\n</code></pre>"},{"location":"api_reference/#enumerations-explained","title":"Enumerations Explained","text":"<ul> <li><code>HandlingMissingEnum</code>: Defines methods to handle missing data.</li> <li><code>\"impute\"</code>: Fill missing values using imputation.</li> <li><code>\"drop\"</code>: Remove rows with missing values.</li> <li> <p><code>\"error\"</code>: Raise an error if missing values are found.</p> </li> <li> <p><code>ImputationMethodEnum</code>: Specifies the imputation technique.</p> </li> <li><code>\"mice\"</code>: Multivariate Imputation by Chained Equations.</li> <li> <p><code>\"simple\"</code>: Simple imputation methods like mean or median.</p> </li> <li> <p><code>FilterMethodEnum</code>: Determines the method for feature filtering based on correlation.</p> </li> <li><code>\"mutual_info\"</code>: Mutual Information.</li> <li><code>\"pearson\"</code>: Pearson Correlation.</li> <li> <p><code>\"lasso\"</code>: Lasso Regression for feature selection.</p> </li> <li> <p><code>SkeletonMethodNameEnum</code>: Names of skeleton identification methods.</p> </li> <li><code>\"BCSL\"</code>: Bootstrap-based Causal Structure Learning.</li> <li> <p><code>\"FAS\"</code>: Fast Adjacency Search.</p> </li> <li> <p><code>ConditionalIndependenceMethodEnum</code>: Methods used for conditional independence testing.</p> </li> <li> <p><code>\"fisherz\"</code>, <code>\"kci\"</code>, <code>\"d_separation\"</code>, <code>\"gsq\"</code>, <code>\"chisq\"</code>, <code>\"mc_fisherz\"</code>, <code>\"mv_fisherz\"</code>.</p> </li> <li> <p><code>MultipleComparisonCorrectionEnum</code>: Techniques to correct for multiple comparisons.</p> </li> <li><code>\"fdr\"</code>: False Discovery Rate.</li> <li> <p><code>\"bonferroni\"</code>: Bonferroni Correction.</p> </li> <li> <p><code>OrientationMethodNameEnum</code>: Names of edge orientation methods.</p> </li> <li><code>\"FCI\"</code>: Fast Causal Inference.</li> <li> <p><code>\"Hill Climbing\"</code>: Hill Climbing Algorithm.</p> </li> <li> <p><code>CausalEffectMethodNameEnum</code>: Names of methods for estimating causal effects.</p> </li> <li><code>'pearson'</code>, <code>'spearman'</code>, <code>'mi'</code>, <code>'kci'</code>, <code>'sem'</code>, <code>'sem-climbing'</code>, <code>'pysr'</code>.</li> </ul>"},{"location":"api_reference/#pysr-integration","title":"PySR Integration","text":"<p>The package integrates with PySR to learn nonlinear structural equations and to score graphs by simulating cyclic structural causal models (SCMs).</p>"},{"location":"api_reference/#symbolic_regression_causal_effect","title":"<code>symbolic_regression_causal_effect</code>","text":"<pre><code>symbolic_regression_causal_effect(\n    df: pd.DataFrame,\n    graph: GeneralGraph,\n    pysr_params: Optional[Dict] = None,\n) -&gt; PySRFitterOutput\n</code></pre> <p>Fits a symbolic regression model for each node using <code>PySRRegressor</code> and returns the learned equations together with the graph that was used for fitting.</p>"},{"location":"api_reference/#pysrscore-and-search_best_graph_climber_pysr","title":"<code>PySRScore</code> and <code>search_best_graph_climber_pysr</code>","text":"<p><code>PySRScore</code> is a scoring function compatible with the hill-climbing utilities. It fits PySR equations for a candidate graph and evaluates them using either the Gaussian pseudo-likelihood or an unbiased maximum mean discrepancy (MMD<sup>2</sup>) estimator. The helper <code>search_best_graph_climber_pysr</code> performs hill climbing over graph structures with this score.</p>"},{"location":"api_reference/#cyclicscmsimulator","title":"<code>CyclicSCMSimulator</code>","text":"<p>After fitting symbolic equations, <code>CyclicSCMSimulator</code> can simulate data from the nonlinear cyclic SCM and compute diagnostics such as pseudo-likelihood and MMD<sup>2</sup>. These diagnostics are used by the PySR hill climber and can also be saved for further analysis.</p>"},{"location":"contributing/","title":"Contributing to CausalPipe","text":"<p>Thank you for considering contributing to CausalPipe! We welcome all kinds of contributions, including:</p> <ul> <li>Bug fixes</li> <li>New features or improvements</li> <li>Documentation improvements</li> </ul>"},{"location":"contributing/#how-to-contribute","title":"How to Contribute","text":"<ol> <li> <p>Fork the Repository: Click the \"Fork\" button at the top of the GitHub page to create a copy of the repository under your GitHub account.</p> </li> <li> <p>Clone Your Fork: Clone the forked repository to your local machine.    <code>bash    git clone https://github.com/your-username/causal-pipe.git</code></p> </li> <li> <p>Create a Branch: Create a new branch for your changes.    <code>bash    git checkout -b feature/new-feature</code></p> </li> <li> <p>Make Your Changes: Implement your changes, whether it's code, tests, or documentation.</p> </li> <li> <p>Commit Your Changes: Commit your changes with a meaningful commit message.    <code>bash    git commit -m \"Added a new feature\"</code></p> </li> <li> <p>Push to GitHub: Push the changes to your GitHub fork.    <code>bash    git push origin feature/new-feature</code></p> </li> <li> <p>Submit a Pull Request: Open a pull request on the original repository and describe the changes you\u2019ve made.</p> </li> </ol> <p>Please ensure your code follows the project's coding standards and includes appropriate tests.</p> <p>For any questions or suggestions, feel free to contact us at albert.buchard@gmail.com.</p>"},{"location":"installation/","title":"Installation","text":"<p>Follow these instructions to install CausalPipe on your system.</p>"},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.6 or higher</li> <li>R (required for <code>lavaan</code> and <code>mice</code> integration)</li> </ul>"},{"location":"installation/#installing-via-pypi","title":"Installing via PyPI","text":"<p>You can install CausalPipe using <code>pip</code>:</p> <pre><code>pip install causal-pipe\n</code></pre>"},{"location":"installation/#additional-dependencies","title":"Additional Dependencies","text":"<p>CausalPipe relies on several Python and R packages. Ensure that the following dependencies are installed:</p>"},{"location":"installation/#python-packages","title":"Python Packages:","text":"<pre><code>numpy&gt;=1.18.0\nscipy&gt;=1.4.0\nscikit-learn&gt;=0.22.0\ncausal-learn==0.1.3.8\nbcsl-python==0.8.0\nrpy2==3.5.16\nnpeet-plus==0.2.0\nnetworkx==3.2.1\npandas==2.2.3\nfactor_analyzer==0.5.1\npysr&gt;=0.19.0  # optional, required for symbolic regression\n</code></pre>"},{"location":"installation/#r-packages","title":"R Packages:","text":"<ul> <li><code>lavaan</code> (for Structural Equation Modeling)</li> <li><code>mice</code> (for multiple imputation)</li> </ul> <p>Ensure that R is properly installed on your system and the necessary packages are available.</p> <p>For symbolic regression and PySR-based features you also need a working Julia installation. See the PySR documentation for details on setting up Julia and its dependencies.</p>"},{"location":"quickstart/","title":"Quick Start","text":""},{"location":"quickstart/#quick-start","title":"Quick Start","text":"<pre><code># Quick Start\n\nThis guide will help you get started with **CausalPipe** by showing how to set up a basic causal analysis pipeline.\n\n## 1. Define Configuration\n\nFirst, define the configuration for your causal discovery pipeline using the `CausalPipeConfig` dataclass. You\u2019ll specify variable types, preprocessing parameters, and methods for skeleton identification and edge orientation.\n\n```python\nfrom causal_pipe.pipe_config import (\n    DataPreprocessingParams,\n    CausalPipeConfig,\n    VariableTypes,\n    FASSkeletonMethod,\n    FCIOrientationMethod,\n    PearsonCausalEffectMethod,\n)\n\nfrom causal_pipe import CausalPipe\n\npreprocessor_params = DataPreprocessingParams(\n        cat_to_codes=False,\n        standardize=True,\n        filter_method=\"mi\",\n        filter_threshold=0.1,\n        handling_missing=\"impute\",\n        imputation_method=\"mice\",\n        use_r_mice=True,\n        full_obs_cols=None,\n)\n\n# Define variable types\nvariable_types = VariableTypes(\n    continuous=[\"age\", \"income\"],\n    ordinal=[\"education_level\"],\n    nominal=[\"gender\", \"diagnosis_1\", \"diagnosis_2\"],\n)\n\n# Initialize the configuration\nconfig = CausalPipeConfig(\n    variable_types=variable_types,\n    preprocessing_params=preprocessor_params,\n    skeleton_method=FASSkeletonMethod(),\n    orientation_method=FCIOrientationMethod(),\n    causal_effect_methods=[PearsonCausalEffectMethod()],\n    study_name=\"causal_analysis\",\n    output_path=\"./output\",\n    show_plots=True,\n    verbose=True,\n)\n\n</code></pre> <p>CausalPipe also ships with a range of specialized classes for each stage of the pipeline. You can mix and match these to suit your analysis:</p> <ul> <li>Skeleton methods: <code>FASSkeletonMethod</code>, <code>BCSLSkeletonMethod</code></li> <li>Orientation methods: <code>FCIOrientationMethod</code>,   <code>HillClimbingOrientationMethod</code></li> <li>Causal effect methods: <code>PearsonCausalEffectMethod</code>,   <code>SpearmanCausalEffectMethod</code>, <code>MICausalEffectMethod</code>,   <code>KCICausalEffectMethod</code>, <code>SEMCausalEffectMethod</code>,   <code>SEMClimbingCausalEffectMethod</code>, <code>PYSRCausalEffectMethod</code>,   <code>PYSRCausalEffectMethodHillClimbing</code></li> </ul>"},{"location":"quickstart/#2-initialize-causalpipe","title":"2. Initialize CausalPipe","text":"<p>Initialize the CausalPipe toolkit by passing in the configuration:</p> <pre><code>from causal_pipe import CausalPipe\n\n# Initialize CausalPipe\ncausal_pipe = CausalPipe(config)\n</code></pre>"},{"location":"quickstart/#3-run-the-causal-discovery-pipeline","title":"3. Run the Causal Discovery Pipeline","text":"<p>Now, you can run the pipeline on your data:</p> <pre><code>import pandas as pd\n\n# Load your dataset\ndata = pd.read_csv(\"your_data.csv\")\n\n# Run the causal discovery pipeline\ncausal_pipe.run_pipeline(data)\n</code></pre>"},{"location":"quickstart/#4-estimating-nonlinear-mechanisms-with-pysr","title":"4. Estimating Nonlinear Mechanisms with PySR","text":"<p><code>CausalPipe</code> can learn symbolic structural equations using PySR. Enable it by adding the <code>pysr</code> causal effect method:</p> <pre><code>from causal_pipe.pipe_config import PYSRCausalEffectMethod\n\nconfig.causal_effect_methods = [\n    PYSRCausalEffectMethod(hc_orient_undirected_edges=True)\n]\n\ncausal_pipe = CausalPipe(config)\nresults = causal_pipe.run_pipeline(data)\nprint(results[\"pysr\"][\"structural_equations\"])\n</code></pre> <p>For more details on the API, see the API Reference.</p>"}]}